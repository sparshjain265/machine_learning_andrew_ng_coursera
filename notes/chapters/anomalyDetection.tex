\chapter{Anomaly Detection}
\section{Example}
\subsection{Aircraft Engine!}
\paragraph{Features:}
\begin{align*}
    x_1 & = \text{heat generated}      \\
    x_2 & = \text{vibration intensity} \\
    \dots
\end{align*}
\paragraph{Dataset:} $\{x^{(1)}, x^{(2)}, \dots, x^{(m)}\}$
\paragraph{Question:} Is $x_{test}$ anomalous?
\paragraph{Answer:} Model $p(x)$ from dataset, and if $p(x_{test}) < \epsilon$
then flag anomaly otherwise OK!

\subsection{Fraud Detection}
Identify unusual users by checking $p(x) < \epsilon$

\subsection{Manufacturing}
Just like Aircraft Engine

\subsection{Monitoring computers in a data center}
Check which system is probably required a review by a system administrator.

\section{Gaussian (Normal) Distribution}
\subsection{Definition}
Say $x \in \R$. If $x$ is distributed \emph{Gaussian} with mean $\mu$ and variance
$\sigma^2$ ($\sigma$ is the standard deviation).
\begin{align*}
    x                   & \sim \normal(\mu, \sigma^2)   \\
    p(x; \mu, \sigma^2) & = \frac{1}{\sqrt{2\pi}\sigma}
    \exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right)       \\
\end{align*}
Bell shaped curve centered at $\mu$ and width varying by $\sigma$

\subsection{Parameter Estimation}
Given a dataset, estimate $\mu$ and $\sigma$ or $\sigma^2$

\subsubsection{Maximum Likelyhood Estimate (MLE):}
\begin{align*}
    \mu      & = \frac{1}{m}\sum_{i=1}^m x^{(i)}          \\
    \sigma^2 & = \frac{1}{m}\sum_{i=1}^m(x^{(i)} - \mu)^2 \\
\end{align*}

\section{Algorithm}
\subsection{Density Estimation}
Training Set: $\{x^{(1)}, \dots, x^{(m)}\}$\\
Each example is $x \in \R$\\
Model $p(x)$ as such:
\begin{align*}
    p(x) & = p(x_1)p(x_2)\dots p(x_n) \\
\end{align*}
Assume each feature is distributed Gaussian independently
\begin{align*}
    x_1  & \sim \normal(\mu_1, \sigma^2_1)                                                  \\
    x_2  & \sim \normal(\mu_2, \sigma^2_2)                                                  \\
    \vdots                                                                                  \\
    x_n  & \sim \normal(\mu_n, \sigma^2_n)                                                  \\
    p(x) & = p(x_1;\mu_1, \sigma^2_1)p(x_2;\mu_2, \sigma^2_2)\dots p(x_n;\mu_n, \sigma^2_n) \\
         & = \prod_{j=1}^n p(x_j; \mu_j, \sigma^2_j)                                        \\
\end{align*}
In practice, it works fine even if the features are not really \emph{independent}.

\subsection{Anomaly Detection Algorithm}
\begin{enumerate}
    \item Choose features $x_i$ that might be indicative of anomaly.
    \item Given a training set $\set{x^{(1)}, \dots, x^{(m)}}$, fit paramters
          $\mu_1, \dots, \mu_n, \sigma^2_1, \dots, \sigma^2_2$
          \begin{align*}
              \mu      & = \frac{1}{m}\sum_{i=1}^m x^{(i)}          \\
              \sigma^2 & = \frac{1}{m}\sum_{i=1}^m(x^{(i)} - \mu)^2 \\
          \end{align*}
    \item Given a new example $x$, compute $p(x)$
          \begin{align*}
              p(x) & = \prod_{j=1}^n p(x_j; \mu_j, \sigma^2_j)     \\
                   & = \prod_{j=1}^n \frac{1}{\sqrt{2\pi}\sigma_j}
              \exp\left(-\frac{(x_j-\mu_j)^2}{2\sigma_j^2}\right)  \\
          \end{align*}
    \item Anomaly if $p(x) < \epsilon$
\end{enumerate}

\section{Developing and Evaluating an Anomaly Detection System}
\subsection{The importance of real-number evaluation}
When developing a learning algorithm (choosing features, etc.),
making decisions is much easier if we have a way of evaluating
our learning algorithm.

Assume we have some labelled data, of anomalous and non-anomalous
examples. ($y = 0$ if normal, $y=1$ if anomalous).

\paragraph{Training set:} $x^{(1)}, x^{(2)}, \dots, x^{(m)}$
(assume normal)

\paragraph{Cross validation set:} $(x_{cv}^{(1)}, y_{cv}^{(1)}), \dots,
    (x_{cv}^{(m_{cv})}, y_{cv}^{(m_{cv})})$

\paragraph{Test set:} $(x_{test}^{(1)}, y_{test}^{(1)}), \dots,
    (x_{test}^{(m_{test})}, y_{test}^{(m_{test})})$

Assume we include examples in cross validation set and test set which
are known to be anomalous.

\subsubsection{Aircraft Engines Example}
Recommended split:
\begin{itemize}
    \item $10000$ good (normal) engines
    \item $20$ - $50$ flawed (anomalous) engines
    \item Training Set: $6000$ good engines
    \item CV: $2000$ good engines, $10$ anomalous
    \item Test: $2000$ good engines, $10$ anomalous
\end{itemize}

\subsection{Algorithm Evaluation}
\begin{enumerate}
    \item Fit model $p(x)$ on training set $\set{x^{(1)}, \dots, x^{(m)}}$
    \item On a cross-validation/test example $x$, predict
          \begin{equation*}
              y = \begin{cases}
                  1 & \text{ if } p(x) < \epsilon \text{ (anomaly)} \\
                  0 & \text{ otherwise}                             \\
              \end{cases}
          \end{equation*}
    \item Possible evaluation metrics \begin{itemize}
              \item True positive, false positive, false negative, true negative
              \item Precision/Recall
              \item F$_1$-score
          \end{itemize}
    \item Can also use cross validation set to choose parameter $\epsilon$
\end{enumerate}

\section{Anomaly Detection vs Supervised Learning}
If we have labelled data, why not use supervised learning?

\begin{tabularx}{0.9\linewidth}{X | X}
    \textbf{Anomaly Detection}                        &
    \textbf{Supervised Learning}                        \\
    \hline                                              \\
    Very small number of positive examples ($y = 1$). &
    Large number of positive and negative examples.     \\
    Large number of negative examples ($y = 0$).        \\
    Many different \emph{types} of anomalies. Hard for
    any algorithm to learn from positive examples what
    the anomalies look like.                          &
    Enough positive examples for algorithm to get a
    sense of what positive examples are like.           \\
    Future anomalies may look
    nothing like any of the anomaly examples we've
    seen so far.                                      &
    Future
    positive examples likely to be similar to ones
    in training set.                                    \\
    Fraud Detection                                   &
    Email spam classification                           \\
    Manufacturing (e.g. aircraft engine)              &
    Weather prediction (sunny/rainy/etc.)               \\
    Monitoring machines in a data center              &
    Cancer classification                               \\
    \vdots                                            &
    \vdots                                              \\
\end{tabularx}

\section{Choosing what features to use}
\subsection{Transformations}
Works fine even if data isn't gaussian, but usually is a good sanity check
for a feature.

If not gaussian, play with different kinds of transformations and get
something similar to gaussian, like $\log$ transformation.

Other transformations:
\begin{align*}
    x_1 & \gets \log{x_1}                  \\
    x_1 & \gets \log{x_2 + c}              \\
    x_3 & \gets \sqrt{x_3} = {x_3}^{\half} \\
    x_4 & \gets {x_4}^{\frac{1}{3}}        \\
\end{align*}

\subsection{Error analysis for anomaly detection}
Want $p(x)$ large for normal examples $x$.

$p(x)$ small for anomalous examples $x$.

\paragraph{Most common problem:}
$p(x)$ is comparable (say, both large) for normal and anomalous examples.

Look at such anomalous examples and try to get a new feature to distinguish.

\subsection{Other techniques:}
Choose features that might take on unusually large or small values in the
event of an anomaly.

\paragraph{Example:} Monitoring computers in a data center running servers.
\begin{align*}
    x_1 & = \text{memory use}      \\
    x_2 & = \text{disk access}     \\
    x_3 & = \text{CPU load}        \\
    x_4 & = \text{network traffic}
\end{align*}
Possible anomaly = infinite loop, so $x_5 = \frac{\text{CPU Load}}{\text{network traffic}}$

\section{Multivariate Gaussian (Normal) Distribution}
\subsubsection{Example}
Monitoring machines in a data center. Consider $x_1 =$ CPU load and $x_2 =$ Memory Use.
An outlier in 2D plot would not be triggered anomalous when treating $x_1$ and $x_2$.

\paragraph{$x \in \R^n$.} Don't model $p(x_1), p(x_2), \dots, $ etc. separately. Model
$p(x)$ all in one go.

\paragraph{Parameters:} $\mu \in \R^n, \Sigma \in \R^{n\times n}$ (covariance matrix)

\paragraph{Equation:}
\begin{align*}
    p(x; \mu, \Sigma)           & = \frac{1}{(2\pi)^{\frac{n}{2}}\card{\Sigma}^\half}
    \exp{\left(-\half\left(x-\mu\right)^T\Sigma^{-1}\left(x-\mu\right)\right)}        \\
    \text{where } \card{\Sigma} & = \text{determinant of } \Sigma =
    \mintinline[escapeinside=||]{octave}{det(|$\Sigma$|)} \text{ (in octave)}         \\
\end{align*}

\section{Anomaly Detection using Multivariate Gaussian Distribution}
\subsection{Model}
\paragraph{Parameters:} $\mu, \Sigma$
\paragraph{Parameter Fitting:} Given training set $\set{x^{(1)}, \dots, x^{(m)}}$
\begin{align*}
    \mu    & = \frac{1}{m}\sum_{i=1}^m x^{(i)}             \\
    \Sigma & = \frac{1}{m}\sum_{i=1}^m
    \left(x^{(i)} - \mu\right)\left(x^{(i)} - \mu\right)^T \\
\end{align*}

\subsection{Anomaly Detection}
\begin{enumerate}
    \item Fit model $p(x)$ by setting $\mu, \Sigma$
    \item Given a new example $x$, compute
          \begin{align*}
              p(x) & = \frac{1}{(2\pi)^{\frac{n}{2}}\card{\Sigma}^\half}
              \exp{\left(-\half\left(x-\mu\right)^T\Sigma^{-1}\left(x-\mu\right)\right)} \\
          \end{align*}
    \item Flag an anomaly if $p(x) < \epsilon$
\end{enumerate}

\subsection{Relationship to original model}
Original model corresponds to multivariate gaussian where the contours of the
gaussian are axis aligned. The contraint (mathematically) is
\begin{align*}
    \Sigma = \begin{bmatrix}
        \sigma_1^2 & 0          & 0      & \dots          & 0          \\
        0          & \sigma_2^2 & 0      & \dots          & 0          \\
        0          & 0          & \ddots &                & 0          \\
        0          & \dots      & 0      & \sigma_{n-1}^2 & 0          \\
        0          & \dots      & 0      & 0              & \sigma_n^2 \\
    \end{bmatrix}
\end{align*}

\begin{tabularx}{0.9\linewidth}{X | X}
    \textbf{Original Model}                                            &
    \textbf{Multivariate Gaussian}                                            \\
    $\prod_{j=1}^n p(x_j; \mu_j, \sigma^2_j)$                          &
    $ \frac{1}{(2\pi)^{\frac{n}{2}}\card{\Sigma}^\half}
    e^{\left(-\half\left(x-\mu\right)^T\Sigma^{-1}\left(x-\mu\right)\right)}$ \\
    Manually create features to capture anomalies where $x_1, x_2$ take unusual
    combination of values.                                             &
    Automatically captures correlations between features.                     \\
    Computationally cheaper (scales better to large $n$, say 100,000). &
    Computationally more expensive.                                           \\
    OK even if $m$ (training set size) is small.                       &
    Must have $m > n$, or else $\Sigma$ is non-invertible.
    (Typical rule of thumb: $m \ge 10n$)                                      \\
\end{tabularx}

\begin{remark}
    If $\Sigma$ is singular (non-invertible), either $m > n$ fails, or
    you have redundant (linearly dependent) features.
\end{remark}

\blfootnote{Check \href{lecture_pdf/Lecture15.pdf}{Lecture15.pdf} for more details.}